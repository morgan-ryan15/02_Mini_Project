---
title: "mn_colleges"
format: html
editor_options: 
  chunk_output_type: console
---

Before you begin acquiring data, describe your motivations for obtaining the data you plan to gather, including questions you hope to answer. 

	As college students, we are interested in data on colleges and universities in Minnesota and the surrounding states. As the “enrollment cliff” nears, questions regarding higher education are particularly interesting. We are curious about how many schools are in each state, the size of the schools, and any other variables that provide college-level information. We want to investigate this state-wide data in hopes of building a better picture of what further education in Minnesota looks like.

After collecting and tidying your data, describe how you might use your data to investigate questions of interest.

We will be cleaning our data and renaming our column names to see the different nuances in this dataset, excluding the defunct institutions, and only focusing on the current and successful colleges in the area. We decided to make a binary column indicating if the college was affiliated with a religious institution, or not; this was to help with the parenthesis issue (colleges that had a religious affiliation had parenthesis to indicate which religion they followed) and ensure that there would not be any in the final tidy dataset. 
Using the polite package, we confirmed that we were scraping the data ethically and responsibly and following good web scraping practices. Before we scraped it, we also made sure we were complying with the website's terms of service.
After scraping and tidying our data, we could easily view the geographic location of each college by making a map (after finding the latitude and longitude for each). Additionally, we could visualize our data in numerous ways. For example, we could make a bar chart of average enrollment with bins for each institution type. 




```{r}
#| include: FALSE

library(tidyverse)
library(stringr)
library(rvest)
library(polite)
library(sf)
library(maps)
library(viridis)
library(leaflet)
library(htmltools)
library(janitor)
```





```{r}
# check that scraping is allowed (Step 0)
robotstxt::paths_allowed("https://en.wikipedia.org/wiki/List_of_colleges_and_universities_in_Minnesota")

# Step 1: read_html()
mn_colleges <- read_html("https://en.wikipedia.org/wiki/List_of_colleges_and_universities_in_Minnesota")

# 2: html_nodes()
tables <- html_nodes(mn_colleges, css = "table") 
tables  # have to guesstimate which table contains climate info

# 3: html_table()
html_table(tables, header = TRUE, fill = TRUE)    # find the right table

mpls_data1 <- html_table(tables, header = TRUE, fill = TRUE)[[2]]  
mpls_data1


mn_data1 <- html_table(tables, header = TRUE, fill = TRUE)[[2]]  
mn_data1

```

```{r}
session <- bow("https://en.wikipedia.org/wiki/List_of_colleges_and_universities_in_Minnesota", force = TRUE)

result <- scrape(session) |>
  html_nodes(css = "table") |> 
  html_table(header = TRUE, fill = TRUE)

mpls_data1 <- result[[2]]

mpls_data1 


mn_data2 <- result[[2]]

mn_data2

```

```{r}
mn_colleges <- mn_data2 |>
  rename(
    "institution" = "Institution",
    "location" = "Location(s)",
    "public_private" = "Control[note 1]",
    "type" = "Type[note 2]",
    "enrollment" = "Enrollment[14](fall 2023)",
    "date_founded" = "Founded"
  ) |>
  filter(!(is.na(public_private))) 

mn_data2 |>
  clean_names() |>
  rename(
    locations = location_s,
    public_private = control_note_1,
    type = type_note_2,
    enrollment = enrollment_14_fall_2023,
    date_founded = founded
  )
  
```

```{r}
rel_or_not <- mn_colleges$public_private

output <- vector()
for(i in length(rel_or_not)) {
  output[i] <- str_split(rel_or_not[i], "\\(")
}
output

for(i in seq_along(rel_or_not)) {
  if (str_extract(rel_or_not[i], "\\(") == TRUE) {
}
}
```


*NEW STUFF BELOW!!!!*

*MN COLLEGES/UNIVERSITY*
```{r}
# check that scraping is allowed (Step 0)
robotstxt::paths_allowed("https://en.wikipedia.org/wiki/List_of_colleges_and_universities_in_Minnesota")

# Step 1: read_html()
mn_colleges <- read_html("https://en.wikipedia.org/wiki/List_of_colleges_and_universities_in_Minnesota")

# 2: html_nodes()
tables <- html_nodes(mn_colleges, css = "table") 
tables  # have to guesstimate which table contains climate info

# 3: html_table()
html_table(tables, header = TRUE, fill = TRUE)    # find the right table

mn_data1 <- html_table(tables, header = TRUE, fill = TRUE)[[2]]  
mn_data1

```

```{r}
session <- bow("https://en.wikipedia.org/wiki/List_of_colleges_and_universities_in_Minnesota", force = TRUE)

result <- scrape(session) |>
  html_nodes(css = "table") |> 
  html_table(header = TRUE, fill = TRUE)

mn_data1 <- result[[2]]

mn_data1 

```

```{r}
#filter and clean minnesota college/university data
mn_data1 <- mn_data1 |>
  clean_names() |>
  select(institution) |>
  mutate(
    #making st bens and st johns "one college" 
    institution = str_trim(str_replace(institution, "and Saint John's University", ""))
  )

mn_list <- as.list(mn_data1$institution)

mn_list

```

*MIAC CONFERENCE*
```{r}
# check that scraping is allowed (Step 0)
robotstxt::paths_allowed("https://en.wikipedia.org/wiki/Minnesota_Intercollegiate_Athletic_Conference")

# Step 1: read_html()
miac_colleges <- read_html("https://en.wikipedia.org/wiki/Minnesota_Intercollegiate_Athletic_Conference")

# 2: html_nodes()
miac_tables <- html_nodes(miac_colleges, css = "table") 
miac_tables  # have to guesstimate which table contains climate info

# 3: html_table()
html_table(miac_tables, header = TRUE, fill = TRUE)    # find the right table

miac_data <- html_table(miac_tables, header = TRUE, fill = TRUE)[[2]]  

miac_data

```

```{r}
#bow and get scrape data
session <- bow("https://en.wikipedia.org/wiki/Minnesota_Intercollegiate_Athletic_Conference", force = TRUE)

miac_result <- scrape(session) |>
  html_nodes(css = "table") |> 
  html_table(header = TRUE, fill = TRUE)

#begin cleaning miac data
miac_data1 <- miac_result[[2]] |>
  clean_names() 

miac_data1 <- miac_data1 |>
  select(institution) |>
  mutate(
    #fixing name consistency
    institution = str_trim(str_replace(institution, "\\[.*\\]", ""), side = "right"),
    institution = str_trim(str_replace(institution, "Mary's University", "Mary's University of Minnesota"), side = "right") 
  )

miac_data1


miac_list <- as.list(miac_data1$institution)
miac_list

```

```{r}
#creating function to look for MN colleges who aren't in the miac
not_in_miac <- function(college_list) {
  not_matched <- vector()
  for(i in college_list){
    if(!(i %in% miac_list)) {
      not_matched <- c(not_matched, i)
    }
  }
  not_matched
}

not_in_miac(mn_list)

```

