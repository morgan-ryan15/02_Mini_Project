---
title: "mn_colleges"
format: html
editor_options: 
  chunk_output_type: console
---

```{r}
#| include: FALSE

library(tidyverse)
library(stringr)
library(rvest)
library(polite)
library(sf)
library(maps)
library(viridis)
library(leaflet)
library(htmltools)
```



```{r}
# check that scraping is allowed (Step 0)
robotstxt::paths_allowed("https://en.wikipedia.org/wiki/List_of_colleges_and_universities_in_Minnesota")

# Step 1: read_html()
mn_colleges <- read_html("https://en.wikipedia.org/wiki/List_of_colleges_and_universities_in_Minnesota")

# 2: html_nodes()
tables <- html_nodes(mn_colleges, css = "table") 
tables  # have to guesstimate which table contains climate info

# 3: html_table()
html_table(tables, header = TRUE, fill = TRUE)    # find the right table
mpls_data1 <- html_table(tables, header = TRUE, fill = TRUE)[[2]]  
mpls_data1

```

Now we wrap the 4 steps above into the `bow` and `scrape` functions from the `polite` package:

```{r}
session <- bow("https://en.wikipedia.org/wiki/List_of_colleges_and_universities_in_Minnesota", force = TRUE)

result <- scrape(session) |>
  html_nodes(css = "table") |> 
  html_table(header = TRUE, fill = TRUE)
mpls_data1 <- result[[2]]

mpls_data1 

```
