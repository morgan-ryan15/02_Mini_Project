---
title: "mn_colleges"
format: html
editor_options: 
  chunk_output_type: console
---


```{r}
# check that scraping is allowed (Step 0)
robotstxt::paths_allowed("https://en.wikipedia.org/wiki/List_of_colleges_and_universities_in_Minnesota")

# Step 1: read_html()
mn_colleges <- read_html("https://en.wikipedia.org/wiki/List_of_colleges_and_universities_in_Minnesota")

# 2: html_nodes()
tables <- html_nodes(mn_colleges_and_universities, css = "table") 
tables  # have to guesstimate which table contains climate info

# 3: html_table()
html_table(tables, header = TRUE, fill = TRUE)    # find the right table
mpls_data1 <- html_table(tables, header = TRUE, fill = TRUE)[[1]]  
mpls_data1
mpls_data2 <- html_table(tables, header = TRUE, fill = TRUE)[[2]]  
mpls_data2
```

Now we wrap the 4 steps above into the `bow` and `scrape` functions from the `polite` package:

```{r}
session <- bow("https://www.usclimatedata.com/climate/minneapolis/minnesota/united-states/usmn0503", force = TRUE)

result <- scrape(session) |>
  html_nodes(css = "table") |> 
  html_table(header = TRUE, fill = TRUE)
mpls_data1 <- result[[1]]
mpls_data2 <- result[[2]]

mpls_data1 
mpls_data2
```
